{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6edac92-c2e3-4fe8-99c2-f77e8b458682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "import colorsys\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import graphviz\n",
    "from statistics import mean, median, mode, stdev\n",
    "import scipy.stats as stats\n",
    "\n",
    "from utils import rubin_combine\n",
    "\n",
    "plt.rcParams['figure.constrained_layout.use'] = False\n",
    "SEED = 7355608\n",
    "\n",
    "predictors = ['base_phq9', 'gad7_sum', 'age', 'sds_sum', 'alc_sum', 'gender', 'education', 'working', 'marital_status', 'race_is_latino', 'race_is_black', 'race_is_asian', 'race_is_multiracial_or_other', 'income_satisfaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5725f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN ANALYSIS\n",
    "data_dir = \"results/main\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2121d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENSITIVITY ANALYSIS: 12-week PHQ-9 instead of 4-week PHQ-9\n",
    "# UNCOMMENT BELOW TO RUN\n",
    "# data_dir = \"results/sens_12wk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1494776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENSITIVITY ANALYSIS: exclude participants with minimal baseline data\n",
    "# UNCOMMENT BELOW TO RUN\n",
    "# data_dir = \"results/sens_exclude_min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71afb7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_data = pd.read_csv(os.path.join(data_dir, \"miceRanger_imputed_formatted_Brighten-v1_all.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a6dae5-0477-4d52-b6d7-be92e6bfab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Generate decision trees for interpretation, using two strategies: \n",
    "    1. Fit a decision tree to the entire dataset, concatenating all imputed versions\n",
    "    2. Fit a decision tree separately to each imputed version of the dataset (focusing on a variable of interest), and examine the distribution\n",
    "'''\n",
    "\n",
    "def man_cmap(cmap, value=1.):\n",
    "    colors = cmap(np.arange(cmap.N))\n",
    "    hls = np.array([colorsys.rgb_to_hls(*c) for c in colors[:,:3]])\n",
    "    hls[:,1] *= value\n",
    "    rgb = np.clip(np.array([colorsys.hls_to_rgb(*c) for c in hls]), 0,1)\n",
    "    return mcolors.LinearSegmentedColormap.from_list(\"\", rgb)\n",
    "\n",
    "for outcome in [\"mdd_improve\"]:\n",
    "    \n",
    "    print(\"OUTCOME: \" + outcome)\n",
    "    \n",
    "    x = pt_data[predictors].copy()\n",
    "        \n",
    "    clf_all = tree.DecisionTreeClassifier(max_depth=2)\n",
    "    clf_all = clf_all.fit(x, pt_data[outcome])\n",
    "    clf_data = tree.export_graphviz(clf_all, out_file=None, feature_names=predictors, class_names=[\"no-\" + outcome, outcome])\n",
    "    graph = graphviz.Source(clf_data)\n",
    "    graph.render(\"decision_tree_\" + outcome)\n",
    "    \n",
    "    #http://www.futurile.net/2016/02/27/matplotlib-beautiful-plots-with-style/\n",
    "    plt.style.use('ggplot')\n",
    "    txt_col = 'k'\n",
    "    plt.rcParams['text.color'] = txt_col\n",
    "    plt.rcParams['axes.labelcolor'] = txt_col\n",
    "    plt.rcParams['xtick.color'] = txt_col\n",
    "    plt.rcParams['ytick.color'] = txt_col\n",
    "    plt.rcParams['axes.labelsize'] = 16\n",
    "    plt.rcParams['axes.labelweight'] = 'bold'\n",
    "    plt.rcParams['xtick.labelsize'] = 16\n",
    "    plt.rcParams['ytick.labelsize'] = 16\n",
    "    plt.rcParams['legend.fontsize'] = 16\n",
    "    plt.rcParams['figure.titlesize'] = 24\n",
    "    plt.tight_layout()\n",
    "\n",
    "    feature_of_interest = \"gad7_sum\"\n",
    "    verbose=False\n",
    "    thresholds = []\n",
    "    for imp in pt_data[\"_Imputation_\"].unique():\n",
    "        pt_data_imp = pt_data[pt_data[\"_Imputation_\"] == imp]\n",
    "\n",
    "        x = pt_data_imp[[feature_of_interest]].copy()\n",
    "            \n",
    "        clf_all = tree.DecisionTreeClassifier(max_depth=1)\n",
    "        clf_all = clf_all.fit(x, pt_data_imp[outcome])\n",
    "\n",
    "        # Get feature and threshold used by the tree\n",
    "        feature = clf_all.tree_.feature[0]  # Get feature index used at root node\n",
    "        threshold = clf_all.tree_.threshold[0]  # Get threshold value used at root node\n",
    "        thresholds.append(threshold)\n",
    "\n",
    "        # Get class distributions for left and right nodes to determine relationship direction\n",
    "        left_dist = clf_all.tree_.value[1]  # Class distribution when feature <= threshold\n",
    "        right_dist = clf_all.tree_.value[2]  # Class distribution when feature > threshold\n",
    "        left_prob = left_dist[0][1] / left_dist[0].sum()  # Probability of {outcome}=True when <= threshold\n",
    "        right_prob = right_dist[0][1] / right_dist[0].sum()  # Probability of {outcome}=True when > threshold\n",
    "\n",
    "        if verbose:\n",
    "            direction = \"more\" if right_prob > left_prob else \"less\"\n",
    "            print(f\"\\nThreshold: {feature_of_interest} = {threshold:.2f}\")\n",
    "            print(f\"Values above threshold are {direction} likely to have {outcome}=True\")\n",
    "    \n",
    "    print(f\"** Statistics for threshold values ({feature_of_interest}) among {pt_data[\"_Imputation_\"].nunique()} imputations: **\")\n",
    "    print(f\"Mean threshold: {mean(thresholds)}\")\n",
    "    print(f\"Median threshold: {median(thresholds)}\")\n",
    "    print(f\"Mode threshold: {mode(thresholds)}\")\n",
    "    print(f\"Standard deviation of thresholds: {stdev(thresholds)}\")\n",
    "    print(f\"Minimum threshold: {min(thresholds)}\")\n",
    "    print(f\"Maximum threshold: {max(thresholds)}\")\n",
    "    print(f\"Unique thresholds: {np.unique(thresholds)}\")\n",
    "    print(f\"Proportion of thresholds equal to median={mode(thresholds)}: {np.mean(np.array(thresholds) == median(thresholds))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295a6595-ae49-4c42-aac7-a7d56982e447",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Generate odds ratios for MDD improvement (using a single-variable threshold of interest), pooling across imputed versions of the dataset using Rubin's rules. \n",
    "'''\n",
    "\n",
    "n_impute=100\n",
    "\n",
    "for arm in [\"all\", \"HealthTips\", \"EVO\", \"iPST\"]:\n",
    "    for group in [\"all\"]:\n",
    "        print(\"STUDY ARM:\", arm)\n",
    "\n",
    "        pt_data = pd.read_csv(os.path.join(data_dir, f\"miceRanger_imputed_formatted_Brighten-v1_{group}.csv\"))\n",
    "\n",
    "        if arm != \"all\":\n",
    "            pt_data = pt_data[pt_data[f\"study_arm_{arm}\"] == 1]\n",
    "\n",
    "        pt_data = pt_data[[\"_Imputation_\", \"gad7_sum\", \"mdd_improve\"]]\n",
    "\n",
    "        #pt_data[\"finish\"] = pt_data[\"bddybocs_tot_recalc_post\"].notnull()\n",
    "        pt_data[\"gad7_below_11\"] = pt_data[\"gad7_sum\"] < 11\n",
    "        pt_data[\"gad7_11_or_higher\"] = pt_data[\"gad7_sum\"] >= 11\n",
    "\n",
    "        for cond in [\"gad7_below_11\", \"gad7_11_or_higher\"]:\n",
    "            print(\"Condition: \" + cond)\n",
    "            for outcome in [\"mdd_improve\"]:\n",
    "                print(\"----OUTCOME: \" + outcome + \"----\")\n",
    "\n",
    "                or_vals = []\n",
    "                or_vars = []\n",
    "                for imp in pt_data[\"_Imputation_\"].unique():\n",
    "                    pt_data_imp = pt_data[pt_data[\"_Imputation_\"] == imp]\n",
    "                    cont_table = np.array([\n",
    "                        [len(pt_data_imp[pt_data_imp[cond] & pt_data_imp[outcome]]), len(pt_data_imp[~pt_data_imp[cond] & pt_data_imp[outcome]])],\n",
    "                        [len(pt_data_imp[pt_data_imp[cond] & ~pt_data_imp[outcome]]), len(pt_data_imp[~pt_data_imp[cond] & ~pt_data_imp[outcome]])]\n",
    "                    ])\n",
    "\n",
    "                    # If any cell of the contingency table is zero, add 0.5 to all cells. \n",
    "                    if np.any(cont_table == 0):\n",
    "                        cont_table = cont_table + 0.5\n",
    "\n",
    "                    # Within-imputation value estimate\n",
    "                    or_vals.append((cont_table[0,0]/cont_table[0,1]) / (cont_table[1,0]/cont_table[1,1]))\n",
    "\n",
    "                    # Within-imputation variance\n",
    "                    or_vars.append(sum([1/val for val in cont_table.reshape(-1)]))\n",
    "\n",
    "                pooled_or, lower_ci, upper_ci, ors, pval = rubin_combine(or_vals, or_vars, log_normal=True)\n",
    "                                                                \n",
    "                print(\"RUBIN OddsR:\", round(pooled_or, 4), \"[\", round(lower_ci, 4), \",\", round(upper_ci, 4), \"].\")\n",
    "                print(\"avg OddsR:\", round(sum(ors)/len(ors), 4))\n",
    "                print(\"p-value:\", pval)\n",
    "                print(\"based on \", len(ors), \" odds ratios\")\n",
    "                \n",
    "            print(\"---------\")\n",
    "    print(\"==============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea00c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import os\n",
    "from utils import rubin_combine\n",
    "\n",
    "def analyze_correlation_with_rubin_combine(df, var1, var2):\n",
    "    \"\"\"\n",
    "    Calculates and pools Pearson and Spearman correlations using the existing rubin_combine function.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. For each imputed dataset, calculates the Pearson and Spearman correlation coefficients.\n",
    "    2. Applies the Fisher Z-transformation to each coefficient (arctanh).\n",
    "    3. Calculates the within-imputation variance for each transformed coefficient.\n",
    "    4. Uses the pre-existing `rubin_combine` function to pool the Z-transformed values.\n",
    "    5. Transforms the pooled Z-score and its confidence interval back to the correlation scale (tanh).\n",
    "    6. Prints the final pooled correlation, confidence interval, and p-value.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing all imputed datasets, with an '_Imputation_' column.\n",
    "    var1 (str): The name of the first variable's column.\n",
    "    var2 (str): The name of the second variable's column.\n",
    "    \"\"\"\n",
    "    pearson_zs = []\n",
    "    pearson_vars = []\n",
    "    spearman_zs = []\n",
    "    spearman_vars = []\n",
    "    sample_sizes = []\n",
    "\n",
    "    imputations = df['_Imputation_'].unique()\n",
    "    m = len(imputations)\n",
    "\n",
    "    for imp in imputations:\n",
    "        df_imp = df[df['_Imputation_'] == imp]\n",
    "        complete_cases = df_imp[[var1, var2]].dropna()\n",
    "        n = len(complete_cases)\n",
    "        assert len(complete_cases) == len(df_imp), \"There shouldn't be any missing data in the imputed versions of the dataset\"\n",
    "        sample_sizes.append(n)\n",
    "\n",
    "        # Variance for Fisher's Z-transform is 1/(n-3), so we need at least 4 samples.\n",
    "        if n < 4:\n",
    "            print(\"Warning: Not enough complete cases to calculate Z-transformedcorrelation.\")\n",
    "            continue\n",
    "\n",
    "        # --- Pearson Correlation ---\n",
    "        pearson_r, _ = stats.pearsonr(complete_cases[var1], complete_cases[var2])\n",
    "        pearson_zs.append(np.arctanh(pearson_r))\n",
    "        pearson_vars.append(1 / (n - 3))\n",
    "\n",
    "        # --- Spearman Correlation ---\n",
    "        spearman_r, _ = stats.spearmanr(complete_cases[var1], complete_cases[var2])\n",
    "        spearman_zs.append(np.arctanh(spearman_r))\n",
    "        spearman_vars.append(1 / (n - 3))\n",
    "\n",
    "    print(f\"Analyzing correlation between '{var1}' and '{var2}' across {m} imputations.\")\n",
    "    print(f\"Average sample size per imputation (after dropping NA): {np.mean(sample_sizes):.1f}\\n\")\n",
    "\n",
    "    # --- Pool Pearson Results ---\n",
    "    if pearson_zs:\n",
    "        # We set log_normal=False because Fisher's Z-scores are normally distributed.\n",
    "        pooled_z_p, lower_z_p, upper_z_p, _, p_val_p = rubin_combine(pearson_zs, pearson_vars, log_normal=False)\n",
    "        \n",
    "        print(\"--- Pooled Pearson Correlation ---\")\n",
    "        # Transform the pooled Z-score and its CI back to the correlation scale\n",
    "        print(f\"Pooled Correlation (r): {np.tanh(pooled_z_p):.5f}\")\n",
    "        print(f\"95% Confidence Interval: [{np.tanh(lower_z_p):.5f}, {np.tanh(upper_z_p):.5f}]\")\n",
    "        print(f\"P-value: {p_val_p:.5f}\")\n",
    "    else:\n",
    "        print(\"Could not calculate Pearson correlation due to insufficient data.\")\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    # --- Pool Spearman Results ---\n",
    "    if spearman_zs:\n",
    "        pooled_z_s, lower_z_s, upper_z_s, _, p_val_s = rubin_combine(spearman_zs, spearman_vars, log_normal=False)\n",
    "        \n",
    "        print(\"--- Pooled Spearman Correlation ---\")\n",
    "        # Transform the pooled Z-score and its CI back to the correlation scale\n",
    "        print(f\"Pooled Correlation (ρ): {np.tanh(pooled_z_s):.5f}\")\n",
    "        print(f\"95% Confidence Interval: [{np.tanh(lower_z_s):.5f}, {np.tanh(upper_z_s):.5f}]\")\n",
    "        print(f\"P-value: {p_val_s:.5f}\")\n",
    "    else:\n",
    "        print(\"Could not calculate Spearman correlation due to insufficient data.\")\n",
    "\n",
    "    print(\"-----\\nNote: Spearman correlation is more appropriate for ordinal data.\")\n",
    "\n",
    "pt_data = pd.read_csv(os.path.join(data_dir, \"miceRanger_imputed_formatted_Brighten-v1_all.csv\"))\n",
    "\n",
    "analyze_correlation_with_rubin_combine(pt_data, 'gad7_sum', 'sds_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f2556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SANITY CHECK: correlation of entire concatenated multiply-imputed dataset (should be similar to Rubin version)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def analyze_gad7_sds_correlation(df):\n",
    "    \"\"\"\n",
    "    Calculate correlation between GAD-7 and SDS scores, handling missing values.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing 'gad7_sum' and 'sds_sum' columns\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary containing correlation statistics and sample sizes\n",
    "    \"\"\"\n",
    "    # Remove rows where either GAD-7 or SDS is missing\n",
    "    complete_cases = df.dropna(subset=['gad7_sum', 'sds_sum'])\n",
    "    \n",
    "    # Calculate number of complete and missing cases\n",
    "    n_complete = len(complete_cases)\n",
    "    n_total = len(df)\n",
    "    n_missing_gad7 = df['gad7_sum'].isna().sum()\n",
    "    n_missing_sds = df['sds_sum'].isna().sum()\n",
    "    \n",
    "    # Calculate correlations if we have at least 2 complete cases\n",
    "    if n_complete >= 2:\n",
    "        pearson_r, pearson_p = stats.pearsonr(\n",
    "            complete_cases['gad7_sum'], \n",
    "            complete_cases['sds_sum']\n",
    "        )\n",
    "        spearman_r, spearman_p = stats.spearmanr(\n",
    "            complete_cases['gad7_sum'], \n",
    "            complete_cases['sds_sum']\n",
    "        )\n",
    "    else:\n",
    "        pearson_r = pearson_p = spearman_r = spearman_p = np.nan\n",
    "    \n",
    "    results = {\n",
    "        'n_total': n_total,\n",
    "        'n_complete': n_complete,\n",
    "        'n_missing_gad7': n_missing_gad7,\n",
    "        'n_missing_sds': n_missing_sds,\n",
    "        'pearson_r': pearson_r,\n",
    "        'pearson_p': pearson_p,\n",
    "        'spearman_r': spearman_r,\n",
    "        'spearman_p': spearman_p\n",
    "    }\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Complete cases: {results['n_complete']} out of {results['n_total']}\")\n",
    "    print(f\"Missing GAD-7: {results['n_missing_gad7']}\")\n",
    "    print(f\"Missing SDS: {results['n_missing_sds']}\")\n",
    "    print(f\"Pearson correlation: r = {results['pearson_r']:.3f}, p = {results['pearson_p']:.3f}\")\n",
    "    print(f\"Spearman correlation: ρ = {results['spearman_r']:.3f}, p = {results['spearman_p']:.3f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "pt_data = pd.read_csv(os.path.join(data_dir, \"miceRanger_imputed_formatted_Brighten-v1_all.csv\"))\n",
    "\n",
    "results = analyze_gad7_sds_correlation(pt_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhealth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
